{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83f0cce",
   "metadata": {},
   "source": [
    "### Using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e33953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas python-Levenshtein spacy nltk textblob tqdm transformers -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "796f4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "data_file = 'DataScientist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53e29d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>index</th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Salary Estimate</th>\n",
       "      <th>Job Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Headquarters</th>\n",
       "      <th>Size</th>\n",
       "      <th>Founded</th>\n",
       "      <th>Type of ownership</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Sector</th>\n",
       "      <th>Revenue</th>\n",
       "      <th>Competitors</th>\n",
       "      <th>Easy Apply</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Hopper\\n3.5</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>Montreal, Canada</td>\n",
       "      <td>501 to 1000 employees</td>\n",
       "      <td>2007</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Travel Agencies</td>\n",
       "      <td>Travel &amp; Tourism</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Data Scientist, Product Analytics</td>\n",
       "      <td>$111K-$181K (Glassdoor est.)</td>\n",
       "      <td>At Noom, we use scientifically proven methods ...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Noom US\\n4.5</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>1001 to 5000 employees</td>\n",
       "      <td>2008</td>\n",
       "      <td>Company - Private</td>\n",
       "      <td>Health, Beauty, &amp; Fitness</td>\n",
       "      <td>Consumer Services</td>\n",
       "      <td>Unknown / Non-Applicable</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  index                          Job Title  \\\n",
       "0           0      0              Senior Data Scientist   \n",
       "1           1      1  Data Scientist, Product Analytics   \n",
       "\n",
       "                Salary Estimate  \\\n",
       "0  $111K-$181K (Glassdoor est.)   \n",
       "1  $111K-$181K (Glassdoor est.)   \n",
       "\n",
       "                                     Job Description  Rating  Company Name  \\\n",
       "0  ABOUT HOPPER\\n\\nAt Hopper, we’re on a mission ...     3.5   Hopper\\n3.5   \n",
       "1  At Noom, we use scientifically proven methods ...     4.5  Noom US\\n4.5   \n",
       "\n",
       "       Location      Headquarters                    Size  Founded  \\\n",
       "0  New York, NY  Montreal, Canada   501 to 1000 employees     2007   \n",
       "1  New York, NY      New York, NY  1001 to 5000 employees     2008   \n",
       "\n",
       "   Type of ownership                   Industry             Sector  \\\n",
       "0  Company - Private            Travel Agencies   Travel & Tourism   \n",
       "1  Company - Private  Health, Beauty, & Fitness  Consumer Services   \n",
       "\n",
       "                    Revenue Competitors Easy Apply  \n",
       "0  Unknown / Non-Applicable          -1         -1  \n",
       "1  Unknown / Non-Applicable          -1         -1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1074400b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_items(df, regex, column_name):\n",
    "    df[column_name] = df['Job Description'].apply(lambda x:re.findall(regex, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b3c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_items(df, column_name):\n",
    "    items = []\n",
    "    for index, row in df.iterrows():\n",
    "        if len(row[column_name]) > 0:\n",
    "            for item in list(row[column_name]):\n",
    "                if (type(item) is tuple) and (len(item) > 1):\n",
    "                    item = item[0]\n",
    "                if item not in items:\n",
    "                    items.append(item)\n",
    "    return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a66206c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emails(df):\n",
    "    email_regex = '[^\\s:|()\\']+@[a-zA-Z0-9\\.]+\\.[a-zA-Z]+'\n",
    "    df['emails'] = df['Job Description'].apply(lambda x: re.findall(email_regex, x))\n",
    "    emails = get_list_of_items(df, 'emails')\n",
    "    return emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f798484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_urls(df):\n",
    "    url_regex = '(http[s]?://(www\\.)?[A-Za-z0-9–_\\.\\-]+\\.[A-Za-z]+/?[A-Za-z0-9$\\–_\\-\\/\\.\\?]*)[\\.)\\\"]*'\n",
    "    df = get_items(df, url_regex, 'urls')\n",
    "    urls = get_list_of_items(df, 'urls')\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bf5838c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4aba160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jsmith@quartethealth.com', 'security@quartethealth.com', 'talent@quartethealth.com', 'accommodations-ext@fb.com', 'talent@ebay.com']\n"
     ]
    }
   ],
   "source": [
    "emails = get_emails(df)\n",
    "print(emails[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4095a493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://www.decode-m.com/', 'https://www.amazon.jobs/en/disability/us.', 'https://www.techatbloomberg.com/nlp/', 'https://bloomberg.com/company/d4gx/', 'https://www.dol.gov/ofccp/regs/compliance/posters/ofccpost.htm']\n"
     ]
    }
   ],
   "source": [
    "urls = get_urls(df)\n",
    "print(urls[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae427e",
   "metadata": {},
   "source": [
    "## Finding similar strings: the Levenshtein distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c15bae82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cdef9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = 'DataScientist.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0b3b616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lavenshtein(input_string, df):\n",
    "    df['distance_to_' + input_string] = df['emails'].apply(lambda x: Levenshtein.distance(input_string, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2420cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_mail_lev(df, email):\n",
    "    df = find_lavenshtein(email, df)\n",
    "    column_name = 'distance_to_' + email\n",
    "    minimum_value_email_index = df[column_name].idxmin()\n",
    "    email = df.loc[minimum_value_email_index]['emails']\n",
    "    return email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a084281b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file, encoding='utf-8')\n",
    "emails  = get_emails(df)\n",
    "new_df = pd.DataFrame(emails, columns=['emails'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2d9931c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emails</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jsmith@quartethealth.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>security@quartethealth.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talent@quartethealth.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accommodations-ext@fb.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>talent@ebay.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       emails\n",
       "0    jsmith@quartethealth.com\n",
       "1  security@quartethealth.com\n",
       "2    talent@quartethealth.com\n",
       "3   accommodations-ext@fb.com\n",
       "4             talent@ebay.com"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54f6e141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rohit.mcdonald@prolim.com\n"
     ]
    }
   ],
   "source": [
    "input_string = \"rohitt.macdonald@prelim.com\"\n",
    "email = get_closest_mail_lev(new_df, input_string)\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f372d9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_jaro(input_string, df):\n",
    "    df['distance_to_' + input_string] = df['emails'].apply(lambda x: Levenshtein.jaro(input_string, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc30d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_email_jaro(df, email):\n",
    "    df = find_jaro(email, df)\n",
    "    column_name = 'distance_to_' + email\n",
    "    maximum_value_email_index = df[column_name].idxmax()\n",
    "    email = df.loc[maximum_value_email_index]['emails']\n",
    "    return email\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c29c121",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file, encoding='utf-8')\n",
    "emails = get_emails(df)\n",
    "new_df = pd.DataFrame(emails, columns=['emails'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bf3753d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rohit.mcdonald@prolim.com\n"
     ]
    }
   ],
   "source": [
    "input_string = \"rohitt.macdonald@prelim.com\"\n",
    "email = get_closest_email_jaro(new_df, input_string)\n",
    "print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2c8d5226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(Levenshtein.jaro_winkler(\"rohit.mcdonald@prolim.com\",\n",
    "      \"rohit.mcdonald@prolim.org\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7fb83ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jellyfish"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5298110b",
   "metadata": {},
   "source": [
    "## Performing named entity recognition using spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "25b77345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install spacy -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33296bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec0d823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abfd8dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6150edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "article = \"\"\"iPhone 12: Apple makes jump to 5G\n",
    "Apple has confirmed its iPhone 12 handsets will be its first to work on faster 5G networks. \n",
    "The company has also extended the range to include a new \"Mini\" model that has a smaller 5.4in screen. \n",
    "The US firm bucked a wider industry downturn by increasing its handset sales over the past year. \n",
    "But some experts say the new features give Apple its best opportunity for growth since 2014, when it revamped its line-up with the iPhone 6. \n",
    "…\n",
    "\"Networks are going to have to offer eye-wateringly attractive deals, and the way they're going to do that is on great tariffs and attractive trade-in deals,\" \n",
    "predicted Ben Wood from the consultancy CCS Insight. Apple typically unveils its new iPhones in September, but opted for a later date this year. \n",
    "It has not said why, but it was widely speculated to be related to disruption caused by the coronavirus pandemic. The firm's shares ended the day 2.7% lower. \n",
    "This has been linked to reports that several Chinese internet platforms opted not to carry the livestream, \n",
    "although it was still widely viewed and commented on via the social media network Sina Weibo.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc1eb0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38db5e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 7 9 CARDINAL\n",
      "Apple 11 16 ORG\n",
      "5 31 32 CARDINAL\n",
      "iPhone 58 64 ORG\n",
      "12 65 67 CARDINAL\n",
      "first 89 94 ORDINAL\n",
      "5 113 114 CARDINAL\n",
      "Mini 185 189 WORK_OF_ART\n",
      "5.4 216 219 CARDINAL\n",
      "US 235 237 GPE\n",
      "the past year 313 326 DATE\n",
      "Apple 372 377 ORG\n",
      "2014 416 420 DATE\n",
      "Ben Wood 643 651 PERSON\n",
      "iPhones 718 725 ORG\n",
      "September 729 738 DATE\n",
      "a later date this year 754 776 DATE\n",
      "2.7% 925 929 PERCENT\n",
      "Chinese 983 990 NORP\n",
      "Sina Weibo 1128 1138 PERSON\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef7dfbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d78ddb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7652f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2aebdca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iPhone 12 0 9 LAW\n",
      "Apple 11 16 ORG\n",
      "5 31 32 CARDINAL\n",
      "G\n",
      "Apple 32 39 ORG\n",
      "iPhone 12 58 67 LAW\n",
      "first 89 94 ORDINAL\n",
      "5 113 114 CARDINAL\n",
      "5.4 216 219 CARDINAL\n",
      "US 235 237 GPE\n",
      "the past year 313 326 DATE\n",
      "Apple 372 377 ORG\n",
      "2014 416 420 DATE\n",
      "Ben Wood 643 651 PERSON\n",
      "CCS Insight 673 684 ORG\n",
      "Apple 686 691 ORG\n",
      "iPhones 718 725 ORG\n",
      "September 729 738 DATE\n",
      "a later date this year 754 776 DATE\n",
      "the day 917 924 DATE\n",
      "2.7% 925 929 PERCENT\n",
      "Chinese 983 990 NORP\n",
      "Sina Weibo 1128 1138 ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed1e295",
   "metadata": {},
   "source": [
    "## Training your own NER model with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c8adc694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.language import Language\n",
    "from spacy.training.example import Example\n",
    "import warnings\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "964b3d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data  = [\n",
    "    (\"A fakir from far-away India travels to Asterix's village and asks Cacofonix to save his land from drought since his singing can cause rain.\", \n",
    "        {'entities':[(39, 46, \"PERSON\"), (66, 75, \"PERSON\")]}),\n",
    "    (\"Cacofonix, accompanied by Asterix and Obelix, must travel to India aboard a magic carpet to save the life of the princess Orinjade, who is to be sacrificed to stop the drought.\", \n",
    "        {'entities':[(0, 9, \"PERSON\"), (26, 33, \"PERSON\"), (38, 44, \"PERSON\"), (61, 66, \"LOC\"), (122, 130, \"PERSON\")]})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6ad0040",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_LABEL = \"GAULISH_WARRIOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe4c031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODIFIED_DATA = [\n",
    "    (\"A fakir from far-away India travels to Asterix's village and asks Cacofonix to save his land from drought since his singing can cause rain.\", \n",
    "        {'entities':[(39, 46, NEW_LABEL), (66, 75, NEW_LABEL)]}),\n",
    "    (\"Cacofonix, accompanied by Asterix and Obelix, must travel to India aboard a magic carpet to save the life of the princess Orinjade, who is to be sacrificed to stop the drought.\", \n",
    "        {'entities':[(0, 9, NEW_LABEL), (26, 33, NEW_LABEL), (38, 44, NEW_LABEL), (61, 66, \"LOC\"), (122, 130, \"PERSON\")]})\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "97316a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 100\n",
    "OUTPUT_DIR = './model_output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a99e8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(nlp, output_dir):\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f4e8ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(input_dir):\n",
    "    nlp = spacy.load(input_dir)\n",
    "    return nlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58e3d203",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model):\n",
    "    if (model is not None):\n",
    "        nlp = spacy.load(model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26633789",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ner_to_model(nlp):\n",
    "    if \"ner\" not in nlp.pipe_names:\n",
    "        #ner = nlp.create_pipe(\"ner\")\n",
    "        ner = nlp.add_pipe(\"ner\")\n",
    "        #nlp.add_pipe(ner, last=True)\n",
    "    else:\n",
    "        ner = nlp.get_pipe(\"ner\")\n",
    "    return (nlp, ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "729907ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_labels(ner, data):\n",
    "    for sentence, annotations in data:\n",
    "        for ent in annotations.get(\"entities\"):\n",
    "            ner.add_label(ent[2])\n",
    "    return ner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2418066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model=None):\n",
    "    nlp = create_model(model)\n",
    "    (nlp, ner) = add_ner_to_model(nlp)\n",
    "    ner = add_labels(ner, Data)\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "        if model is None:\n",
    "            nlp.begin_training()\n",
    "        for itn in range(N_ITER):\n",
    "            random.shuffle(Data)\n",
    "            losses = {}\n",
    "            batches = minibatch(Data, size=compounding(4.0, 32.0, 1.001))\n",
    "            for batch in batches:\n",
    "                texts, annotations = zip(*batch)\n",
    "                \n",
    "                example = []\n",
    "                # Update the model with iterating each text\n",
    "                for i in range(len(texts)):\n",
    "                    doc = nlp.make_doc(texts[i])\n",
    "                    example.append(Example.from_dict(doc, annotations[i]))\n",
    "                \n",
    "                # Update the model\n",
    "                nlp.update(example, drop=0.5, losses=losses)\n",
    "                #nlp.update(texts,annotations,drop=0.5,losses=losses,)\n",
    "            print(\"Losses\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ecd09307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_new_entity_type(model=None):\n",
    "    random.seed(0)\n",
    "    nlp = create_model(model)\n",
    "    (nlp, ner) = add_ner_to_model(nlp)\n",
    "    ner = add_labels(ner,  MODIFIED_DATA)\n",
    "    if model is None:\n",
    "        optimizer = nlp.begin_training()\n",
    "    else:\n",
    "        optimizer = nlp.resume_training()\n",
    "    move_names = list(ner.move_names)\n",
    "    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes), warnings.catch_warnings():\n",
    "        warnings.filterwarnings(\"once\", category=UserWarning, module='spacy')\n",
    "        sizes = compounding(1.0, 4.0, 1.001)\n",
    "        for itn in range(N_ITER):\n",
    "            random.shuffle(MODIFIED_DATA)\n",
    "            batches = minibatch(MODIFIED_DATA, size=sizes)\n",
    "            losses = {}\n",
    "\n",
    "            for batch in batches:\n",
    "                example = []\n",
    "                texts, annotations = zip(*batch)\n",
    "                for i in range(len(texts)):\n",
    "                    doc = nlp.make_doc(texts[i])\n",
    "                    example.append(Example.from_dict(doc, annotations[i]))\n",
    "                # Update the model\n",
    "                nlp.update(example, sgd=optimizer, drop=0.35, losses=losses)\n",
    "\n",
    "                #nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n",
    "            print(\"Losses\", losses)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "04fe858f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(nlp, data):\n",
    "    for text, annotations in data:\n",
    "        doc = nlp(text)\n",
    "        for ent in doc.ents:\n",
    "            print(ent.text, ent.start_char, ent.end_char, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "153f607a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def without_training(data=Data):\n",
    "    nlp = spacy.load('en_core_web_sm')\n",
    "    test_model(nlp, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e8659eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "India 22 27 GPE\n",
      "Asterix 39 46 GPE\n",
      "Cacofonix 66 75 PERSON\n",
      "Cacofonix 0 9 PERSON\n",
      "Asterix 26 33 GPE\n",
      "Obelix 38 44 GPE\n",
      "India 61 66 GPE\n"
     ]
    }
   ],
   "source": [
    "without_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb62b410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 56.69999474287033}\n",
      "Losses {'ner': 54.958800137043}\n",
      "Losses {'ner': 52.94415831565857}\n",
      "Losses {'ner': 50.565078139305115}\n",
      "Losses {'ner': 48.28574687242508}\n",
      "Losses {'ner': 44.68732714653015}\n",
      "Losses {'ner': 42.361946761608124}\n",
      "Losses {'ner': 38.65636965632439}\n",
      "Losses {'ner': 33.976553559303284}\n",
      "Losses {'ner': 29.553545236587524}\n",
      "Losses {'ner': 25.5546837747097}\n",
      "Losses {'ner': 21.668899461627007}\n",
      "Losses {'ner': 18.45509660243988}\n",
      "Losses {'ner': 16.126677813008428}\n",
      "Losses {'ner': 14.615515949204564}\n",
      "Losses {'ner': 11.444966023322195}\n",
      "Losses {'ner': 12.032228186842985}\n",
      "Losses {'ner': 12.276712302525993}\n",
      "Losses {'ner': 10.90361583068443}\n",
      "Losses {'ner': 12.593374493546435}\n",
      "Losses {'ner': 12.421660574680573}\n",
      "Losses {'ner': 10.493042279020301}\n",
      "Losses {'ner': 10.675639409106225}\n",
      "Losses {'ner': 10.657256406044326}\n",
      "Losses {'ner': 9.764247692161007}\n",
      "Losses {'ner': 8.330677633130108}\n",
      "Losses {'ner': 9.920391023857519}\n",
      "Losses {'ner': 9.579842207487673}\n",
      "Losses {'ner': 9.518379069428192}\n",
      "Losses {'ner': 8.529923015390523}\n",
      "Losses {'ner': 7.433694325532997}\n",
      "Losses {'ner': 6.3485096627118764}\n",
      "Losses {'ner': 5.701265392552159}\n",
      "Losses {'ner': 6.34416675598186}\n",
      "Losses {'ner': 4.413413196034526}\n",
      "Losses {'ner': 4.5878300303068045}\n",
      "Losses {'ner': 4.371063698376929}\n",
      "Losses {'ner': 3.2870626773017193}\n",
      "Losses {'ner': 3.3211119926096444}\n",
      "Losses {'ner': 3.0731410936814427}\n",
      "Losses {'ner': 3.939252035658151}\n",
      "Losses {'ner': 4.0348142235671665}\n",
      "Losses {'ner': 2.062619960290652}\n",
      "Losses {'ner': 1.9049505108615936}\n",
      "Losses {'ner': 3.5888799266182883}\n",
      "Losses {'ner': 1.9903569343180905}\n",
      "Losses {'ner': 2.223640835002872}\n",
      "Losses {'ner': 1.7242298987067657}\n",
      "Losses {'ner': 1.4136794706968359}\n",
      "Losses {'ner': 1.9901121334753007}\n",
      "Losses {'ner': 2.7439869293627766}\n",
      "Losses {'ner': 1.5010266093749898}\n",
      "Losses {'ner': 2.3775356586664365}\n",
      "Losses {'ner': 1.6791343517008945}\n",
      "Losses {'ner': 1.5671828523940456}\n",
      "Losses {'ner': 1.0758693614673807}\n",
      "Losses {'ner': 2.2640393145142146}\n",
      "Losses {'ner': 0.9886596825622885}\n",
      "Losses {'ner': 1.0974210144227958}\n",
      "Losses {'ner': 0.7851342117941725}\n",
      "Losses {'ner': 0.7034431537621182}\n",
      "Losses {'ner': 0.84622659544153}\n",
      "Losses {'ner': 1.3569646496963788}\n",
      "Losses {'ner': 1.0622848982253312}\n",
      "Losses {'ner': 1.306511759686061}\n",
      "Losses {'ner': 1.665557847065666}\n",
      "Losses {'ner': 0.568482646404478}\n",
      "Losses {'ner': 1.267108004912328}\n",
      "Losses {'ner': 0.1875970936550083}\n",
      "Losses {'ner': 0.2969173495209069}\n",
      "Losses {'ner': 1.8138899286190657}\n",
      "Losses {'ner': 1.2709744393487399}\n",
      "Losses {'ner': 0.1002426527987554}\n",
      "Losses {'ner': 0.15190710866744625}\n",
      "Losses {'ner': 0.10613466036829709}\n",
      "Losses {'ner': 0.5513754383649458}\n",
      "Losses {'ner': 0.7144891615819384}\n",
      "Losses {'ner': 0.3389733529020201}\n",
      "Losses {'ner': 0.33147615573705436}\n",
      "Losses {'ner': 0.08290880084886146}\n",
      "Losses {'ner': 0.00407342484308186}\n",
      "Losses {'ner': 0.011875248713618738}\n",
      "Losses {'ner': 1.4323746994119488}\n",
      "Losses {'ner': 0.15585422746217303}\n",
      "Losses {'ner': 0.003047234796566949}\n",
      "Losses {'ner': 1.4746568968753913}\n",
      "Losses {'ner': 0.0076939659824303}\n",
      "Losses {'ner': 0.0028163115780409317}\n",
      "Losses {'ner': 0.006821790789455646}\n",
      "Losses {'ner': 1.2810658176527934}\n",
      "Losses {'ner': 0.6333912371393835}\n",
      "Losses {'ner': 0.33855623910065813}\n",
      "Losses {'ner': 0.0028674862848529284}\n",
      "Losses {'ner': 0.07714751067202168}\n",
      "Losses {'ner': 0.000994467985233452}\n",
      "Losses {'ner': 0.0001677674667000676}\n",
      "Losses {'ner': 0.7270576222293709}\n",
      "Losses {'ner': 0.0006168971705538013}\n",
      "Losses {'ner': 0.2584522224827511}\n",
      "Losses {'ner': 0.007202865093203381}\n",
      "Asterix 39 46 PERSON\n",
      "Cacofonix 66 75 PERSON\n",
      "Cacofonix 0 9 PERSON\n",
      "Asterix 26 33 PERSON\n",
      "Obelix 38 44 PERSON\n",
      "India 61 66 LOC\n",
      "Orinjade 122 130 PERSON\n"
     ]
    }
   ],
   "source": [
    "#without_training()\n",
    "model = \"en_core_web_sm\"\n",
    "#nlp = train_model(model)\n",
    "nlp = train_model()\n",
    "#nlp = train_model_new_entity_type(model)\n",
    "test_model(nlp, Data)\n",
    "save_model(nlp, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f5569522",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses {'ner': 12.873662403094183}\n",
      "Losses {'ner': 11.086281906108713}\n",
      "Losses {'ner': 9.338196985599572}\n",
      "Losses {'ner': 11.315571699796344}\n",
      "Losses {'ner': 8.744863866056008}\n",
      "Losses {'ner': 10.208964536775992}\n",
      "Losses {'ner': 7.507466658867859}\n",
      "Losses {'ner': 7.56369555522287}\n",
      "Losses {'ner': 8.063255207437237}\n",
      "Losses {'ner': 7.409186578850578}\n",
      "Losses {'ner': 6.506002846174155}\n",
      "Losses {'ner': 5.7376775395907345}\n",
      "Losses {'ner': 5.649352904390099}\n",
      "Losses {'ner': 5.812398416121681}\n",
      "Losses {'ner': 5.546093613420467}\n",
      "Losses {'ner': 6.806875053608479}\n",
      "Losses {'ner': 6.429044631896701}\n",
      "Losses {'ner': 5.899568408334076}\n",
      "Losses {'ner': 5.18329166008607}\n",
      "Losses {'ner': 3.953846889725753}\n",
      "Losses {'ner': 4.801641977863412}\n",
      "Losses {'ner': 4.040012741388409}\n",
      "Losses {'ner': 2.2176201349668645}\n",
      "Losses {'ner': 0.8099534462355038}\n",
      "Losses {'ner': 1.4320689444691652}\n",
      "Losses {'ner': 0.07602201369348904}\n",
      "Losses {'ner': 0.04305899091809806}\n",
      "Losses {'ner': 0.09661513995518156}\n",
      "Losses {'ner': 0.0132913786064634}\n",
      "Losses {'ner': 0.10997407550623182}\n",
      "Losses {'ner': 0.0017938825090121858}\n",
      "Losses {'ner': 0.030833509552965453}\n",
      "Losses {'ner': 0.00031769990782532626}\n",
      "Losses {'ner': 0.00017446245348928674}\n",
      "Losses {'ner': 0.00041323287569453856}\n",
      "Losses {'ner': 7.895045959814548e-05}\n",
      "Losses {'ner': 0.00037176993137003484}\n",
      "Losses {'ner': 5.781145908880668e-05}\n",
      "Losses {'ner': 3.358817898963804e-05}\n",
      "Losses {'ner': 0.004305740702903806}\n",
      "Losses {'ner': 0.0002574739066141939}\n",
      "Losses {'ner': 3.4335921417729394e-06}\n",
      "Losses {'ner': 1.1960837754553069e-06}\n",
      "Losses {'ner': 7.027996916992468e-05}\n",
      "Losses {'ner': 1.0492368708158223e-06}\n",
      "Losses {'ner': 0.12332838002652272}\n",
      "Losses {'ner': 1.9294343572511026e-06}\n",
      "Losses {'ner': 9.631592942138621e-07}\n",
      "Losses {'ner': 9.98739712351445e-06}\n",
      "Losses {'ner': 2.94443148882946e-06}\n",
      "Losses {'ner': 1.8017005524139667e-06}\n",
      "Losses {'ner': 4.16140793154822e-05}\n",
      "Losses {'ner': 0.00020024346376851547}\n",
      "Losses {'ner': 3.954402325517099e-08}\n",
      "Losses {'ner': 1.9762078265349883e-07}\n",
      "Losses {'ner': 4.1531403800959774e-07}\n",
      "Losses {'ner': 3.733402894977818e-07}\n",
      "Losses {'ner': 2.7823802699070003e-07}\n",
      "Losses {'ner': 0.00020499512855847227}\n",
      "Losses {'ner': 1.2937726307164444e-06}\n",
      "Losses {'ner': 1.6171175280733668e-06}\n",
      "Losses {'ner': 7.469128118757941e-08}\n",
      "Losses {'ner': 3.098076426883682e-06}\n",
      "Losses {'ner': 3.1952114725429306e-05}\n",
      "Losses {'ner': 0.00033295229397169114}\n",
      "Losses {'ner': 1.619543706042121e-06}\n",
      "Losses {'ner': 1.9446445636811123e-06}\n",
      "Losses {'ner': 1.3619457051503456e-07}\n",
      "Losses {'ner': 7.950815950625132e-06}\n",
      "Losses {'ner': 6.225504784148394e-06}\n",
      "Losses {'ner': 5.623582515459045e-06}\n",
      "Losses {'ner': 0.0009052238020261802}\n",
      "Losses {'ner': 3.7237834187331375e-06}\n",
      "Losses {'ner': 5.919161759882911e-06}\n",
      "Losses {'ner': 1.7049214439464293e-07}\n",
      "Losses {'ner': 4.2444953832342585e-06}\n",
      "Losses {'ner': 3.0159777065489677e-07}\n",
      "Losses {'ner': 1.362688786967068e-07}\n",
      "Losses {'ner': 4.971483796096446e-07}\n",
      "Losses {'ner': 3.684650932959381e-07}\n",
      "Losses {'ner': 2.0092687570879746e-09}\n",
      "Losses {'ner': 1.96589917801314e-08}\n",
      "Losses {'ner': 4.4092621581734693e-07}\n",
      "Losses {'ner': 3.368040240583891e-08}\n",
      "Losses {'ner': 8.569093063665296e-07}\n",
      "Losses {'ner': 1.9143622194210297e-06}\n",
      "Losses {'ner': 4.938423881959533e-08}\n",
      "Losses {'ner': 0.003097228557634744}\n",
      "Losses {'ner': 2.026270427630962e-09}\n",
      "Losses {'ner': 7.565686118226712e-05}\n",
      "Losses {'ner': 3.407418920271351e-05}\n",
      "Losses {'ner': 0.0002745507609164707}\n",
      "Losses {'ner': 5.193768223998207e-05}\n",
      "Losses {'ner': 0.00043176149111004403}\n",
      "Losses {'ner': 4.19011236673761e-09}\n",
      "Losses {'ner': 1.412713361390208e-06}\n",
      "Losses {'ner': 1.4809689279857304e-07}\n",
      "Losses {'ner': 6.66541075470847e-08}\n",
      "Losses {'ner': 2.5939724686098097e-05}\n",
      "Losses {'ner': 6.148065600767702e-10}\n",
      "Asterix 39 46 GAULISH_WARRIOR\n",
      "Cacofonix 66 75 GAULISH_WARRIOR\n",
      "Cacofonix 0 9 GAULISH_WARRIOR\n",
      "Asterix 26 33 GAULISH_WARRIOR\n",
      "Obelix 38 44 GAULISH_WARRIOR\n",
      "India 61 66 LOC\n",
      "Orinjade 122 130 PERSON\n"
     ]
    }
   ],
   "source": [
    "model = \"en_core_web_sm\"\n",
    "nlp = train_model_new_entity_type(model)\n",
    "test_model(nlp, MODIFIED_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4ff385",
   "metadata": {},
   "source": [
    "## Discovering sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c29ada99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/bat/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "19c2ebe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0ca59319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"I love going to school!\", \"I hate going to school!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e00101aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8621afc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blob_sentiment(sentence):\n",
    "    result = TextBlob(sentence).sentiment\n",
    "    print(sentence, result.polarity)\n",
    "    return result.polarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2597a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nltk_sentiment(sentence):\n",
    "    ss = sid.polarity_scores(sentence)\n",
    "    print(sentence, ss['compound'])\n",
    "    return ss['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49832046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love going to school! 0.6696\n",
      "I hate going to school! -0.6114\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    sentiment = get_nltk_sentiment(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f72627b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love going to school! 0.625\n",
      "I hate going to school! -1.0\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    sentiment = get_blob_sentiment(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67452310",
   "metadata": {},
   "source": [
    "### Sentiment for short texts using LSTM: Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "85400265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# os.environ['AUTOGRAPH_VERBOSITY'] = '5'\n",
    "# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "# Verbosity is now 5\n",
    "\n",
    "# tf.autograph.set_verbosity(0)\n",
    "# Verbosity is now 0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from wordseg import segment\n",
    "import html\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from langdetect import detect\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "#from Chapter04.lstm_classification import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6953966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(history):\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2dd026b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NUM_WORDS = 50000\n",
    "EMBEDDING_DIM = 500\n",
    "twitter_csv = \"training.1600000.processed.noemoticon.csv\"\n",
    "english_twitter = \"./twitter_english.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3728ebe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82039f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_english(df, save_path):\n",
    "    df['language'] = df['tweet'].progress_apply(lambda t: lang_detect(t))\n",
    "    df = df[df['language']=='en']\n",
    "    df.to_csv(save_path, encoding='latin1', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78fb72d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, save_path, num_datapoints=80000):\n",
    "    df = pd.read_csv(filename, encoding='latin1')\n",
    "    df.columns = ['sentiment', 'id', 'date', 'query','username', 'tweet']\n",
    "    df = pd.concat([df.head(num_datapoints), df.tail(num_datapoints)])\n",
    "    df = filter_english(df, save_path)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7ae8d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lang_detect(text):\n",
    "    lang = \"\"\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "    except LangDetectException:\n",
    "        lang = \"None\"\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea1c2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hashtags(tweet):\n",
    "    matches = re.findall(r'#[a-z0-9]+', tweet)\n",
    "    for match in matches:\n",
    "        tweet = re.sub(match, ' '.join(segment(match)[0]), tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d981cd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    #Lowercase all tweets\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: t.lower())\n",
    "    #Decode HTML\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: html.unescape(t))\n",
    "    #Remove @ mentions\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: re.sub(r'@[A-Za-z0-9]+','',t))\n",
    "    #Remove URLs\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t:re.sub('https?://[A-Za-z0-9./]+','',t))\n",
    "    #Segment hashtags\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: segment_hashtags(t))\n",
    "    #Remove remaining non-alpha characters\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: re.sub(\"[^a-zA-Z]\", \" \", t))\n",
    "    #Re-label positive tweets with 1 instead of 4\n",
    "    df['sentiment'] = df['sentiment'].apply(lambda t: 1 if t==4 else t)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a561c39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    y_pred = np.where(y_pred > 0.5, 1,0)\n",
    "    y_pred = [pred[0] for pred in y_pred]\n",
    "    print(classification_report(y_test, y_pred, labels=[0, 1], target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7a2e3b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df):\n",
    "    tokenizer = Tokenizer(num_words=MAX_NUM_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "    tokenizer.fit_on_texts(df['tweet'].values)\n",
    "    save_tokenizer(tokenizer, 'twitter_tokenizer.pkl')\n",
    "    X = tokenizer.texts_to_sequences(df['tweet'].values)\n",
    "    X = pad_sequences(X)\n",
    "    y = df['sentiment'].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, \n",
    "                                                        random_state=42, stratify=df['sentiment'])\n",
    "    optimizer = tf.keras.optimizers.Adam(0.00001)\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(MAX_NUM_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "    model.add(SpatialDropout1D(0.2))\n",
    "    model.add(LSTM(100, dropout=0.5, recurrent_dropout=0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    \n",
    "    epochs = 15\n",
    "    batch_size = 64\n",
    "    \n",
    "    es = EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_split=0.3, callbacks=es)\n",
    "    \n",
    "    accr = model.evaluate(X_test, y_test)\n",
    "    print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))\n",
    "    model.save('twitter_model.h5')\n",
    "    evaluate(model, X_test, y_test)\n",
    "    plot_model(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4c051b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tokenizer(tokenizer, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5c0522f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f795ade92f1c45c58a6c0b82e0821e12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/160000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = get_data(twitter_csv, 'twitter_english.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4bf0971d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d56ea230ad8d4a73b36a78a6cf4b414e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "959885e8dc1a4d669dbe3f1c98f142a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e5bfb12323843809291ffbd5a846c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39d5140ed02240219aaed8d3c009f386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "894e4073e6534419b5b085dc78898b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55383297cc7b449bb1dd42b3be22ab71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ebb6e9fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1302/1302 [==============================] - 790s 604ms/step - loss: 0.6886 - accuracy: 0.5685 - val_loss: 0.6820 - val_accuracy: 0.6211\n",
      "Epoch 2/15\n",
      "1302/1302 [==============================] - 711s 546ms/step - loss: 0.6642 - accuracy: 0.6349 - val_loss: 0.6333 - val_accuracy: 0.6653\n",
      "Epoch 3/15\n",
      "1302/1302 [==============================] - 811s 623ms/step - loss: 0.6093 - accuracy: 0.6837 - val_loss: 0.5846 - val_accuracy: 0.7087\n",
      "Epoch 4/15\n",
      "1302/1302 [==============================] - 945s 725ms/step - loss: 0.5686 - accuracy: 0.7168 - val_loss: 0.5553 - val_accuracy: 0.7260\n",
      "Epoch 5/15\n",
      "1302/1302 [==============================] - 803s 617ms/step - loss: 0.5410 - accuracy: 0.7400 - val_loss: 0.5351 - val_accuracy: 0.7430\n",
      "Epoch 6/15\n",
      "1302/1302 [==============================] - 849s 652ms/step - loss: 0.5206 - accuracy: 0.7537 - val_loss: 0.5204 - val_accuracy: 0.7534\n",
      "Epoch 7/15\n",
      "1302/1302 [==============================] - 830s 638ms/step - loss: 0.5055 - accuracy: 0.7649 - val_loss: 0.5087 - val_accuracy: 0.7600\n",
      "Epoch 8/15\n",
      "1302/1302 [==============================] - 1382s 1s/step - loss: 0.4916 - accuracy: 0.7719 - val_loss: 0.4992 - val_accuracy: 0.7642\n",
      "Epoch 9/15\n",
      "1302/1302 [==============================] - 1193s 916ms/step - loss: 0.4786 - accuracy: 0.7795 - val_loss: 0.4915 - val_accuracy: 0.7703\n",
      "Epoch 10/15\n",
      "1302/1302 [==============================] - 1641s 1s/step - loss: 0.4696 - accuracy: 0.7849 - val_loss: 0.4850 - val_accuracy: 0.7723\n",
      "Epoch 11/15\n",
      "1302/1302 [==============================] - 1495s 1s/step - loss: 0.4601 - accuracy: 0.7898 - val_loss: 0.4796 - val_accuracy: 0.7749\n",
      "Epoch 12/15\n",
      "1302/1302 [==============================] - 1178s 905ms/step - loss: 0.4524 - accuracy: 0.7941 - val_loss: 0.4751 - val_accuracy: 0.7766\n",
      "Epoch 13/15\n",
      "1302/1302 [==============================] - 1090s 837ms/step - loss: 0.4452 - accuracy: 0.7975 - val_loss: 0.4712 - val_accuracy: 0.7784\n",
      "Epoch 14/15\n",
      "1302/1302 [==============================] - 959s 736ms/step - loss: 0.4396 - accuracy: 0.8017 - val_loss: 0.4681 - val_accuracy: 0.7808\n",
      "Epoch 15/15\n",
      "1302/1302 [==============================] - 895s 687ms/step - loss: 0.4329 - accuracy: 0.8057 - val_loss: 0.4659 - val_accuracy: 0.7816\n",
      "930/930 [==============================] - 30s 33ms/step - loss: 0.4581 - accuracy: 0.7863\n",
      "Test set\n",
      "  Loss: 0.458\n",
      "  Accuracy: 0.786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.78      0.79     14954\n",
      "    positive       0.78      0.79      0.79     14784\n",
      "\n",
      "    accuracy                           0.79     29738\n",
      "   macro avg       0.79      0.79      0.79     29738\n",
      "weighted avg       0.79      0.79      0.79     29738\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_model(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9425cde6",
   "metadata": {},
   "source": [
    "## Using BERT for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d576e3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['AUTOGRAPH_VERBOSITY'] = '5'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1'\n",
    "# Verbosity is now 5\n",
    "\n",
    "tf.autograph.set_verbosity(0)\n",
    "# Verbosity is now 0\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertForSequenceClassification\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import html\n",
    "import re\n",
    "from wordseg import segment\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724fbd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model(history):\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e2206f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, train_column_name, gold_column_name, test_percent=20):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[train_column_name], df[gold_column_name], test_size=test_percent, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "59d3a88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_hashtags(tweet):\n",
    "    matches = re.findall(r'#[a-z0-9]+', tweet)\n",
    "    for match in matches:\n",
    "        tweet = re.sub(match, ' '.join(segment(match)[0]), tweet)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "068d6c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    #Lowercase all tweets\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: t.lower())\n",
    "    #Decode HTML\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: html.unescape(t))\n",
    "    #Remove @ mentions\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: re.sub(r'@[A-Za-z0-9]+','',t))\n",
    "    #Remove URLs\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: re.sub('https?://[A-Za-z0-9./]+','',t))\n",
    "    #Segment hashtags\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: segment_hashtags(t))\n",
    "    #Remove remaining non-alpha characters\n",
    "    df['tweet'] = df['tweet'].progress_apply(lambda t: re.sub(\"[^a-zA-Z]\", \" \", t))\n",
    "    #Re-label positive tweets with 1 instead of 4\n",
    "    df['sentiment'] = df['sentiment'].apply(lambda t: 1 if t==4 else t)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21f77c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "DATASET_SIZE = 4000\n",
    "english_twitter = \"./twitter_english.csv\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "max_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a0d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_data(df):\n",
    "    input_ids_list = []\n",
    "    token_type_ids_list = []\n",
    "    attention_mask_list = []\n",
    "    label_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        tweet = row['tweet']\n",
    "        label = row['sentiment']\n",
    "        bert_input = tokenizer.encode_plus(\n",
    "                        tweet,                      \n",
    "                        add_special_tokens = True, # add [CLS], [SEP]\n",
    "                        max_length = max_length, # max length of the text that can go to BERT\n",
    "                        padding='max_length', # add [PAD] tokens\n",
    "                        return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "                        truncation=True\n",
    "            )        \n",
    "        input_ids_list.append(bert_input['input_ids'])\n",
    "        token_type_ids_list.append(bert_input['token_type_ids'])\n",
    "        attention_mask_list.append(bert_input['attention_mask'])\n",
    "        label_list.append([label])\n",
    "    return tf.data.Dataset.from_tensor_slices((input_ids_list, attention_mask_list, token_type_ids_list, label_list)).map(map_inputs_to_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0970690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_inputs_to_dict(input_ids, attention_masks, token_type_ids, label):\n",
    "    return {\n",
    "      \"input_ids\": input_ids,\n",
    "      \"token_type_ids\": token_type_ids,\n",
    "      \"attention_mask\": attention_masks,\n",
    "  }, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05b84ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df, size=int(DATASET_SIZE/2)):\n",
    "    df = clean_data(df)\n",
    "    df = pd.concat([df.head(size),df.tail(size)])\n",
    "    df = df.sample(frac = 1)\n",
    "    ds = encode_data(df)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bec6e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_train_val_datasets(ds, size=DATASET_SIZE, batch_size=BATCH_SIZE):\n",
    "    ds.shuffle(32)\n",
    "    train_size = int(0.7 * size)\n",
    "    val_size = int(0.15 * size)\n",
    "    test_size = int(0.15 * size)\n",
    "    train_dataset = ds.take(train_size).batch(batch_size)\n",
    "    test_dataset = ds.skip(train_size)\n",
    "    val_dataset = test_dataset.skip(test_size).batch(batch_size)\n",
    "    test_dataset = test_dataset.take(test_size).batch(batch_size)\n",
    "    return (train_dataset, test_dataset, val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc6251af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_model(ds, export_dir):\n",
    "    (train_dataset, test_dataset, val_dataset) = get_test_train_val_datasets(ds)\n",
    "    learning_rate = 2e-5\n",
    "    number_of_epochs = 1\n",
    "    model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
    "    bert_history = model.fit(train_dataset, epochs=number_of_epochs, validation_data=val_dataset)\n",
    "    model.save_pretrained(export_dir)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e1360a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_model(export_dir):\n",
    "    model = TFBertForSequenceClassification.from_pretrained(export_dir)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b2c1e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_existing_file(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    df = df[['tweet', 'sentiment']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31507f62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33948a35ff7479188e8486786f664c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc30d50a041e4a43b358c2b1c4d4c960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "852bccc253ab47b390d3eb4234a2b56b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6df36d12bb407c8883ef701f3a88b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c8f5fc4c2ca431eb7314bdf392bd7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d22153503564ee6ae36a42bc3697830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148688 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = read_existing_file(english_twitter)\n",
    "dataset = prepare_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996be22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f8b97c63ca0>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:From /Users/bat/miniconda3/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "74/88 [========================>.....] - ETA: 33:20 - loss: 0.5971 - accuracy: 0.6736"
     ]
    }
   ],
   "source": [
    "model = fine_tune_model(dataset,'./bert_twitter_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf47abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_example(input_text):\n",
    "    tokenized = tokenizer.tokenize(input_text)\n",
    "    bert_input = tokenizer.encode_plus(\n",
    "                    input_text,                      \n",
    "                    add_special_tokens = True, # add [CLS], [SEP]\n",
    "                    max_length = max_length, # max length of the text that can go to BERT\n",
    "                    pad_to_max_length = True, # add [PAD] tokens\n",
    "                    return_attention_mask = True, # add attention mask to not focus on pad tokens\n",
    "                    return_tensors='tf',\n",
    "                    padding='max_length'\n",
    "        )\n",
    "    return bert_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a30bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_example(model_path, tweet):\n",
    "    model = load_existing_model(model_path)\n",
    "    bert_input = encode_example(tweet)\n",
    "    tf_output = model.predict([bert_input['input_ids'], bert_input['token_type_ids'], bert_input['attention_mask']])[0]\n",
    "    tf_pred = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
    "    new_label = np.argmax(tf_pred, axis=-1)\n",
    "    print(new_label)\n",
    "    return new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e44c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_new_example('./bert_twitter_model', 'I hate going to the school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f29fba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = []\n",
    "    for tweet in X_test:\n",
    "        bert_input = encode_example(tweet)\n",
    "        tf_output = model.predict([bert_input['input_ids'], bert_input['token_type_ids'], bert_input['attention_mask']])[0]\n",
    "        tf_pred = tf.nn.softmax(tf_output, axis=1).numpy()[0]\n",
    "        new_label = np.argmax(tf_pred, axis=-1)\n",
    "        y_pred.append(new_label)\n",
    "    print(classification_report(y_test, y_pred, labels=[0, 1], target_names=['negative', 'positive']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_evaluate_existing_model(export_dir, num_points=200):\n",
    "    model = load_existing_model(export_dir)\n",
    "    df = read_existing_file(english_twitter)\n",
    "    df = clean_data(df)\n",
    "    df = pd.concat([df.head(num_points),df.tail(num_points)])\n",
    "    (X_train, X_test, y_train, y_test) = split_dataset(df, 'tweet', 'sentiment',20)\n",
    "    evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51da09ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_and_evaluate_existing_model('bert_twitter_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473ea76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
