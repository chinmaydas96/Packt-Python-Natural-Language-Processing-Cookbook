{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "90028ccc",
   "metadata": {},
   "source": [
    "## LDA topic modeling with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9275432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "import nltk\n",
    "import string\n",
    "import csv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b45f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def read_in_csv(csv_file):\n",
    "    with open(csv_file, 'r', encoding='utf-8') as fp:\n",
    "        reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "        data_read = [row for row in reader]\n",
    "    return data_read\n",
    "\n",
    "def get_stopwords(path):\n",
    "    stopwords = read_in_csv(path)\n",
    "    stopwords = [word[0] for word in stopwords]\n",
    "    stemmed_stopwords = [stemmer.stem(word) for word in stopwords]\n",
    "    stopwords = stopwords + stemmed_stopwords\n",
    "    return stopwords\n",
    "\n",
    "stopwords = get_stopwords('stopwords.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d84074c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    filtered_token = [t for t in tokens if t not in string.punctuation]\n",
    "    stems = [stemmer.stem(t) for t in filtered_token]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1aaea25",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_dataset = '../Chapter04/bbc-text.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7330445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_count_vectorizer(documents):\n",
    "    count_vectorizer = CountVectorizer(stop_words=stopwords, tokenizer=tokenize_and_stem)\n",
    "    data = count_vectorizer.fit_transform(documents)\n",
    "    return count_vectorizer, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eea20aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "    df['text'] = \\\n",
    "    df['text'].apply(lambda x: re.sub(r'\\d', '', x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e29a0d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_fit_lda(data, num_topics):\n",
    "    lda = LDA(n_components=num_topics, n_jobs=-1)\n",
    "    lda.fit(data)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd0bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_common_words_for_topics(model, vectorizer, n_top_words):\n",
    "    words = vectorizer.get_feature_names()\n",
    "    word_dict = {}\n",
    "    for topic_index, topic in enumerate(model.components_):\n",
    "        this_topic_words = [words[i] for i in topic.argsort()[:-n_top_words - 1:-1]]\n",
    "        word_dict[topic_index] = this_topic_words\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56aed9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_topic_words(word_dict):\n",
    "    for key in word_dict.keys():\n",
    "        print(f'topic {key}')\n",
    "        print(\"\\t\", word_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49b76c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(bbc_dataset)\n",
    "df = clean_data(df)\n",
    "documents = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49897302",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topic = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03cc7103",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, data = create_count_vectorizer(documents)\n",
    "lda = create_and_fit_lda(data, num_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a070541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0\n",
      "\t ['game', 'play', 'player', 'time', 'england', 'year', 'first', 'back', 'win', 'get']\n",
      "topic 1\n",
      "\t ['elect', 'labour', 'year', 'parti', 'say', 'blair', 'minist', 'm', 'peopl', 'tori']\n",
      "topic 2\n",
      "\t ['peopl', 'year', 'use', 'servic', 'uk', 'new', 'mobil', 'phone', 'technolog', 'music']\n",
      "topic 3\n",
      "\t ['film', 'best', 'award', 'm', 'star', 'year', 'includ', 'show', 'director', 'actor']\n",
      "topic 4\n",
      "\t ['compani', 'bn', 'year', 'firm', 'm', 'share', 'market', 'new', 'sale', 'bank']\n"
     ]
    }
   ],
   "source": [
    "topic_words = get_most_common_words_for_topics(lda, vectorizer, 10)\n",
    "print_topic_words(topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b5fbec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20d709e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"lda_sklearn.pkl\"\n",
    "vectorizer_path = \"vectorizer.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31ca9347",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_example = \"\"\"Manchester United players slumped\n",
    "to the turf at full-time in Germany on Tuesday in\n",
    "acknowledgement of what their latest pedestrian firsthalf display had cost them. The 3-2 loss at RB Leipzig\n",
    "means United will not be one of the 16 teams in the draw\n",
    "for the knockout stages of the Champions League. And\n",
    "this is not the only price for failure. The damage will\n",
    "be felt in the accounts, in the dealings they have with\n",
    "current and potentially future players and in the faith\n",
    "the fans have placed in manager Ole Gunnar Solskjaer.\n",
    "With Paul Pogba's agent angling for a move for his\n",
    "client and ex-United defender Phil Neville speaking of a\n",
    "\"witchhunt\" against his former team-mate Solskjaer, BBC\n",
    "Sport looks at the ramifications and reaction to a big\n",
    "loss for United.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7863b973",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(lda, lda_path, vect, vect_path):\n",
    "    pickle.dump(lda, open(lda_path, 'wb'))\n",
    "    pickle.dump(vect, open(vect_path, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f08a901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_example(lda, vect, example):\n",
    "    vectorized = vect.transform([example])\n",
    "    topic = lda.transform(vectorized)\n",
    "    print(topic)\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5e21541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.67490796 0.09460827 0.00351055 0.00353303 0.22344018]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.67490796, 0.09460827, 0.00351055, 0.00353303, 0.22344018]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new_example(lda, vectorizer, new_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6348331",
   "metadata": {},
   "source": [
    "## LDA topic modeling with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2103557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1596abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_dataset = '../Chapter04/bbc-text.csv'\n",
    "stopwords_file_path = \"stopwords.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd5701ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words = stopwords.words('english')\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def read_in_csv(csv_file):\n",
    "    with open(csv_file, 'r', encoding='utf-8') as fp:\n",
    "        reader = csv.reader(fp, delimiter=',', quotechar='\"')\n",
    "        data_read = [row for row in reader]\n",
    "    return data_read\n",
    "\n",
    "def get_stopwords(path):\n",
    "    stopwords = read_in_csv(path)\n",
    "    stopwords = [word[0] for word in stopwords]\n",
    "    stemmed_stopwords = [stemmer.stem(word) for word in stopwords]\n",
    "    stopwords = stopwords + stemmed_stopwords\n",
    "    return stopwords\n",
    "\n",
    "stopwords = get_stopwords(stopwords_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c0d9a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'[^\\w\\s]', ' ', x))\n",
    "    df['text'] = df['text'].apply(lambda x: re.sub(r'\\d', '', x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba2e4e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = clean_data(df)\n",
    "    df['text'] = df['text'].apply(lambda x: simple_preprocess(x, deacc=True))\n",
    "    df['text'] = df['text'].apply(lambda x: [word for word in x if word not in stopwords])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38344c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lda_model(id_dict, corpus, num_topics):\n",
    "    lda_model = LdaModel(corpus=corpus, id2word=id_dict, num_topics=num_topics,\n",
    "                        random_state=100, chunksize=100, passes=10)\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eff26aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(bbc_dataset)\n",
    "df = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ae4ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['text'].values\n",
    "id_dict = corpora.Dictionary(texts)\n",
    "corpus = [id_dict.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee59605b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_topics = 5\n",
    "lda_model = create_lda_model(id_dict, corpus, number_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "81cefef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.010*\"net\" + 0.008*\"software\" + 0.007*\"users\" + 0.007*\"information\" + '\n",
      "  '0.007*\"people\" + 0.006*\"attacks\" + 0.006*\"computer\" + 0.006*\"data\" + '\n",
      "  '0.006*\"use\" + 0.005*\"firms\"'),\n",
      " (1,\n",
      "  '0.012*\"people\" + 0.006*\"blair\" + 0.005*\"labour\" + 0.005*\"new\" + '\n",
      "  '0.005*\"mobile\" + 0.005*\"party\" + 0.004*\"get\" + 0.004*\"government\" + '\n",
      "  '0.004*\"uk\" + 0.004*\"election\"'),\n",
      " (2,\n",
      "  '0.012*\"film\" + 0.009*\"best\" + 0.006*\"music\" + 0.006*\"year\" + 0.005*\"show\" + '\n",
      "  '0.005*\"new\" + 0.004*\"uk\" + 0.004*\"awards\" + 0.004*\"films\" + 0.004*\"last\"'),\n",
      " (3,\n",
      "  '0.008*\"game\" + 0.006*\"england\" + 0.006*\"first\" + 0.006*\"time\" + '\n",
      "  '0.006*\"year\" + 0.005*\"players\" + 0.005*\"win\" + 0.005*\"world\" + 0.005*\"back\" '\n",
      "  '+ 0.005*\"last\"'),\n",
      " (4,\n",
      "  '0.010*\"bn\" + 0.010*\"year\" + 0.007*\"sales\" + 0.005*\"last\" + '\n",
      "  '0.004*\"government\" + 0.004*\"new\" + 0.004*\"market\" + 0.004*\"growth\" + '\n",
      "  '0.004*\"spending\" + 0.004*\"economic\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4b64e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_example = \"\"\"Manchester United players slumped to the\n",
    "turf\n",
    "at full-time in Germany on Tuesday in acknowledgement of\n",
    "what their\n",
    "latest pedestrian first-half display had cost them. The\n",
    "3-2 loss at\n",
    "RB Leipzig means United will not be one of the 16 teams\n",
    "in the draw\n",
    "for the knockout stages of the Champions League. And this\n",
    "is not the\n",
    "only price for failure. The damage will be felt in the\n",
    "accounts, in\n",
    "the dealings they have with current and potentially\n",
    "future players\n",
    "and in the faith the fans have placed in manager Ole\n",
    "Gunnar Solskjaer.\n",
    "With Paul Pogba's agent angling for a move for his client\n",
    "and ex-United\n",
    "defender Phil Neville speaking of a \"witchhunt\" against\n",
    "his former team-mate\n",
    "Solskjaer, BBC Sport looks at the ramifications and\n",
    "reaction to a big loss for United.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "994b304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(lda, lda_path, id_dict, dict_path):\n",
    "    lda.save(lda_path)\n",
    "    id_dict.save(dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c8dc54dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(lda_path, dict_path):\n",
    "    lda = LdaModel.load(lda_path)\n",
    "    id_dict = corpora.Dictionary.load(dict_path)\n",
    "    return (lda, id_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a6fd2a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_new_example(lda, id_dict, input_string):\n",
    "    input_list = clean_text(input_string)\n",
    "    bow = id_dict.doc2bow(input_list)\n",
    "    topics = lda[bow]\n",
    "    print(topics)\n",
    "    return topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "162a59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(input_string):\n",
    "    input_string = re.sub(r'[^\\w\\s]', ' ', input_string)\n",
    "    input_string = re.sub(r'\\d', '', input_string)\n",
    "    input_list = simple_preprocess(input_string)\n",
    "    input_list = [word for word in input_list if word not in stopwords]\n",
    "    return input_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fb59c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"lda_gensim.pkl\"\n",
    "dict_path = \"id_dict.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f7ce4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(lda_model, model_path, id_dict, dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "37903d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.023436217), (1, 0.036407087), (3, 0.7584859), (4, 0.17845576)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 0.023436217), (1, 0.036407087), (3, 0.7584859), (4, 0.17845576)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new_example(lda_model, id_dict, new_example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14a10aa",
   "metadata": {},
   "source": [
    "## NMF topic modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47793d88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
