{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43079881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n! pip install inflect\\n! python -m spacy download en_core_web_md\\n! pip install textacy\\n! pip install neuralcoref\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "! pip install inflect\n",
    "! python -m spacy download en_core_web_md\n",
    "! pip install textacy\n",
    "! pip install neuralcoref\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd94c0e",
   "metadata": {},
   "source": [
    "## Counting nouns – plural and singular nouns\n",
    "\n",
    "* Determine whether a noun is plural or singular\n",
    "* Turn plural nouns into singular nouns and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f42a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from Chapter01.pos_tagging import pos_tag_nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b39a13a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import inflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d319b852",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Chapter01/sherlock_holmes_1.txt', 'r', encoding=\"utf-8\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5c9cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = text.replace('\\n', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4acb019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To Sherlock Holmes she is always _the_ woman. I have seldom heard him mention her under any other name. In his eyes she eclipses and predominates the whole of her sex. It was not that he felt any emotion akin to love for Irene Adler. All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind. He was, I take it, the most perfect reasoning and observing machine that the world has seen, but as a lover he would have placed himself in a false position. He never spoke of the softer passions, save with a gibe and a sneer. They were admirable things for the observer—excellent for drawing the veil from men’s motives and actions. But for the trained reasoner to admit such intrusions into his own delicate and finely adjusted temperament was to introduce a distracting factor which might throw a doubt upon all his mental results. Grit in a sensitive instrument, or a crack in one of his own high-power lenses, would not be more disturbing than a strong emotion in a nature such as his. And yet there was but one woman to him, and that woman was the late Irene Adler, of dubious and questionable memory.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caef0dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('To', 'TO'),\n",
       " ('Sherlock', 'NNP'),\n",
       " ('Holmes', 'NNP'),\n",
       " ('she', 'PRP'),\n",
       " ('is', 'VBZ')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_with_pos = pos_tag_nltk(text)\n",
    "words_with_pos[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "247ac7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(words_with_pos):\n",
    "    nouns_set = [\"NN\", \"NNS\"]\n",
    "    nouns = [word for word in words_with_pos if word[1] in nouns_set]\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "889c23b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 'NN'), ('name', 'NN'), ('eyes', 'NNS'), ('whole', 'NN'), ('sex', 'NN'), ('emotion', 'NN'), ('akin', 'NN'), ('emotions', 'NNS'), ('cold', 'NN'), ('precise', 'NN'), ('mind', 'NN'), ('reasoning', 'NN'), ('machine', 'NN'), ('world', 'NN'), ('lover', 'NN'), ('position', 'NN'), ('passions', 'NNS'), ('gibe', 'NN'), ('sneer', 'NN'), ('things', 'NNS'), ('observer—excellent', 'NN'), ('veil', 'NN'), ('men', 'NNS'), ('motives', 'NNS'), ('actions', 'NNS'), ('reasoner', 'NN'), ('intrusions', 'NNS'), ('delicate', 'NN'), ('temperament', 'NN'), ('distracting', 'NN'), ('factor', 'NN'), ('doubt', 'NN'), ('results', 'NNS'), ('instrument', 'NN'), ('crack', 'NN'), ('high-power', 'NN'), ('lenses', 'NNS'), ('emotion', 'NN'), ('nature', 'NN'), ('woman', 'NN'), ('woman', 'NN'), ('memory', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "nouns = get_nouns(words_with_pos)\n",
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bc8fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plural_nltk(noun_info):\n",
    "    pos = noun_info[1]\n",
    "    if pos == \"NNS\":\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ccc7889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_plural_nltk(nouns[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de800276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plural_wn(noun):\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemma = wnl.lemmatize(noun, 'n')\n",
    "    plural = True if noun is not lemma else False\n",
    "    return plural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdc86bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_plural_wn('women')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdcd4aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plural(singular_noun):\n",
    "    p = inflect.engine()\n",
    "    return p.plural(singular_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bce8216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runs'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_plural('run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da8a877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_singular(plural_noun):\n",
    "    p = inflect.engine()\n",
    "    plural = p.singular_noun(plural_noun)\n",
    "    if plural :\n",
    "        return plural\n",
    "    else:\n",
    "        return plural_noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff467853",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'emotion'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_singular('emotions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33d1b374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plurals_wn(words_with_pos):\n",
    "    other_nouns = []\n",
    "    for noun_info in words_with_pos:\n",
    "        word = noun_info[0]\n",
    "        plural = is_plural_wn(word)\n",
    "        if plural:\n",
    "            singular = get_singular(word)\n",
    "            other_nouns.append(singular)\n",
    "        else:\n",
    "            plural = get_plural(word)\n",
    "            other_nouns.append(plural)\n",
    "    return other_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4ed7836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['women',\n",
       " 'names',\n",
       " 'eye',\n",
       " 'wholes',\n",
       " 'sexes',\n",
       " 'emotions',\n",
       " 'akins',\n",
       " 'emotion',\n",
       " 'colds',\n",
       " 'precises',\n",
       " 'minds',\n",
       " 'reasonings',\n",
       " 'machines',\n",
       " 'worlds',\n",
       " 'lovers',\n",
       " 'positions',\n",
       " 'passion',\n",
       " 'gibes',\n",
       " 'sneers',\n",
       " 'thing',\n",
       " 'observer—excellents',\n",
       " 'veils',\n",
       " 'mens',\n",
       " 'motive',\n",
       " 'action',\n",
       " 'reasoners',\n",
       " 'intrusion',\n",
       " 'delicates',\n",
       " 'temperaments',\n",
       " 'distractings',\n",
       " 'factors',\n",
       " 'doubts',\n",
       " 'result',\n",
       " 'instruments',\n",
       " 'cracks',\n",
       " 'high-powers',\n",
       " 'lens',\n",
       " 'emotions',\n",
       " 'natures',\n",
       " 'women',\n",
       " 'women',\n",
       " 'memories']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_nouns_wn = plurals_wn(nouns)\n",
    "other_nouns_wn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724a9194",
   "metadata": {},
   "source": [
    "## Getting the dependency parse\n",
    "\n",
    "* A dependency parse is a tool that shows dependencies in a sentence. \n",
    "\n",
    "* For example, in the sentence The cat wore a hat, the root of the sentence in the verb, wore, and both the subject, the cat, and the object, a hat, are dependents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d3b8d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a3e65f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I have seldom heard him mention her under any other name.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14d7a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd6ce4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8ce2f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t nsubj \t nominal subject\n",
      "have \t aux \t auxiliary\n",
      "seldom \t advmod \t adverbial modifier\n",
      "heard \t ROOT \t None\n",
      "him \t nsubj \t nominal subject\n",
      "mention \t ccomp \t clausal complement\n",
      "her \t dobj \t direct object\n",
      "under \t prep \t prepositional modifier\n",
      "any \t det \t determiner\n",
      "other \t amod \t adjectival modifier\n",
      "name \t pobj \t object of preposition\n",
      ". \t punct \t punctuation\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, '\\t', token.dep_,'\\t', spacy.explain(token.dep_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25240dd4",
   "metadata": {},
   "source": [
    "* ROOT is the main word that all the other words depend on, usually the verb.\n",
    "\n",
    "\n",
    "* \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efea2040",
   "metadata": {},
   "source": [
    "* To explore the dependency parse structure, we can use the attributes of the Token class. Using its ancestors and children attributes,\n",
    "\n",
    "\n",
    "* We can get the **tokens that this token depends on** and the **tokens that depend on it**, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf279758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "['heard']\n",
      "have\n",
      "['heard']\n",
      "seldom\n",
      "['heard']\n",
      "heard\n",
      "[]\n",
      "him\n",
      "['mention', 'heard']\n",
      "mention\n",
      "['heard']\n",
      "her\n",
      "['mention', 'heard']\n",
      "under\n",
      "['mention', 'heard']\n",
      "any\n",
      "['name', 'under', 'mention', 'heard']\n",
      "other\n",
      "['name', 'under', 'mention', 'heard']\n",
      "name\n",
      "['under', 'mention', 'heard']\n",
      ".\n",
      "['heard']\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)\n",
    "    ancestor = [t.text for t in token.ancestors]\n",
    "    print(ancestor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea58084c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "[]\n",
      "have\n",
      "[]\n",
      "seldom\n",
      "[]\n",
      "heard\n",
      "['I', 'have', 'seldom', 'mention', '.']\n",
      "him\n",
      "[]\n",
      "mention\n",
      "['him', 'her', 'under']\n",
      "her\n",
      "[]\n",
      "under\n",
      "['name']\n",
      "any\n",
      "[]\n",
      "other\n",
      "[]\n",
      "name\n",
      "['any', 'other']\n",
      ".\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)\n",
    "    children = [t.text for t in token.children]\n",
    "    print(children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cc383eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "['I']\n",
      "have\n",
      "['have']\n",
      "seldom\n",
      "['seldom']\n",
      "heard\n",
      "['I', 'have', 'seldom', 'heard', 'him', 'mention', 'her', 'under', 'any', 'other', 'name', '.']\n",
      "him\n",
      "['him']\n",
      "mention\n",
      "['him', 'mention', 'her', 'under', 'any', 'other', 'name']\n",
      "her\n",
      "['her']\n",
      "under\n",
      "['under', 'any', 'other', 'name']\n",
      "any\n",
      "['any']\n",
      "other\n",
      "['other']\n",
      "name\n",
      "['any', 'other', 'name']\n",
      ".\n",
      "['.']\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)\n",
    "    subtree = [t.text for t in token.subtree]\n",
    "    print(subtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1ba0a2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"36237de2337c4af08574dc516f818a49-0\" class=\"displacy\" width=\"1975\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">have</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">seldom</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">heard</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">him</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">mention</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">her</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">under</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">any</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">other</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">name.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-3\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,266.5 L762,254.5 778,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-4\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 920.0,89.5 920.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,266.5 L928.0,254.5 912.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-5\" stroke-width=\"2px\" d=\"M945,264.5 C945,177.0 1090.0,177.0 1090.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1090.0,266.5 L1098.0,254.5 1082.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-6\" stroke-width=\"2px\" d=\"M945,264.5 C945,89.5 1270.0,89.5 1270.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270.0,266.5 L1278.0,254.5 1262.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,89.5 1795.0,89.5 1795.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-8\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,177.0 1790.0,177.0 1790.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,266.5 L1637,254.5 1653,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-36237de2337c4af08574dc516f818a49-0-9\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,2.0 1800.0,2.0 1800.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-36237de2337c4af08574dc516f818a49-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1800.0,266.5 L1808.0,254.5 1792.0,254.5\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc,jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740c15b",
   "metadata": {},
   "source": [
    "* https://www.analyticsvidhya.com/blog/2020/07/part-of-speechpos-tagging-dependency-parsing-and-constituency-parsing-in-nlp/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa84bd",
   "metadata": {},
   "source": [
    "## Splitting sentences into clauses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f2f3302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6621b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"He eats cheese, but he won't eat ice cream.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59031430",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33037091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He \t 0 \t PRON \t nsubj \t ['eats'] \t []\n",
      "eats \t 1 \t VERB \t ROOT \t [] \t ['He', 'cheese', ',', 'but', 'eat']\n",
      "cheese \t 2 \t NOUN \t dobj \t ['eats'] \t []\n",
      ", \t 3 \t PUNCT \t punct \t ['eats'] \t []\n",
      "but \t 4 \t CCONJ \t cc \t ['eats'] \t []\n",
      "he \t 5 \t PRON \t nsubj \t ['eat', 'eats'] \t []\n",
      "wo \t 6 \t AUX \t aux \t ['eat', 'eats'] \t []\n",
      "n't \t 7 \t PART \t neg \t ['eat', 'eats'] \t []\n",
      "eat \t 8 \t VERB \t conj \t ['eats'] \t ['he', 'wo', \"n't\", 'cream', '.']\n",
      "ice \t 9 \t NOUN \t compound \t ['cream', 'eat', 'eats'] \t []\n",
      "cream \t 10 \t NOUN \t dobj \t ['eat', 'eats'] \t ['ice']\n",
      ". \t 11 \t PUNCT \t punct \t ['eat', 'eats'] \t []\n"
     ]
    }
   ],
   "source": [
    "# dependency parse information. It will help us determine how to split the sentence into clauses.\n",
    "\n",
    "for token in doc:\n",
    "    ancestors = [t.text for t in token.ancestors]\n",
    "    children = [t.text for t in token.children]\n",
    "    print(token.text, \"\\t\", token.i, \"\\t\", token.pos_, \"\\t\",\n",
    "         token.dep_, \"\\t\", ancestors, '\\t', children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10add569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the token that has a dependency tag of ROOT\n",
    "\n",
    "def find_root_of_sentence(doc):\n",
    "    root_token = None\n",
    "    for token in doc:\n",
    "        if token.dep_ =='ROOT':\n",
    "            root_token = token\n",
    "    return root_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8656cbd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eats"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_token = find_root_of_sentence(doc)\n",
    "root_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "43504f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now use the following function to find the other verbs in the sentence:\n",
    "\n",
    "def find_other_verbs(doc, root_token):\n",
    "    other_verbs = []\n",
    "    for token in doc:\n",
    "        ancestors = list(token.ancestors)\n",
    "\n",
    "        if token.pos_ == 'VERB' and len(ancestors)==1 and ancestors[0] == root_token:\n",
    "            other_verbs.append(token)\n",
    "            \n",
    "    return other_verbs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b110be58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eats"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ec45af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[eat]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_verbs = find_other_verbs(doc, root_token)\n",
    "other_verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe572ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the following function to find the token spans for each verb:\n",
    "# find the beginning and ending index for the verb.\n",
    "\n",
    "def get_clause_token_span_for_verb(verb, doc, all_verbs):\n",
    "    first_token_index = len(doc)\n",
    "    last_token_index = 0\n",
    "    this_verb_children = list(verb.children)\n",
    "    \n",
    "    for child in this_verb_children:\n",
    "        if child not in all_verbs:\n",
    "            if child.i < first_token_index:\n",
    "                first_token_index = child.i\n",
    "            \n",
    "            if child.i > last_token_index:\n",
    "                last_token_index = child.i\n",
    "    return (first_token_index, last_token_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0785bd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 4), (5, 11)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will put together all the verbs in one array and process each using the preceding function. \n",
    "# This will return a tuple of start and end indices for each verb's clause:\n",
    "\n",
    "token_spans = []\n",
    "all_verbs = [root_token] + other_verbs\n",
    "\n",
    "for other_verb in all_verbs:\n",
    "    first_token_index, last_token_index = get_clause_token_span_for_verb(other_verb, doc, all_verbs)\n",
    "    token_spans.append((first_token_index, last_token_index))\n",
    "token_spans    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0c1668ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[He eats cheese,, he won't eat ice cream]\n"
     ]
    }
   ],
   "source": [
    "# Using the start and end indices, we can now put together token spans for each clause. \n",
    "# We sort the sentence_clauses list at the end so that the clauses are in the order they appear in the sentence:\n",
    "\n",
    "sentence_clauses = []\n",
    "\n",
    "for token_span in token_spans:\n",
    "    start = token_span[0]\n",
    "    end = token_span[1]\n",
    "    \n",
    "    if start < end:\n",
    "        clause = doc[start:end]\n",
    "        sentence_clauses.append(clause)\n",
    "        \n",
    "sentence_clauses = sorted(sentence_clauses, key=lambda tup: tup[0])\n",
    "print(sentence_clauses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a7b58c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He eats cheese,', \"he won't eat ice cream\"]\n"
     ]
    }
   ],
   "source": [
    "clauses_text = [clause.text for clause in sentence_clauses]\n",
    "print(clauses_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16925052",
   "metadata": {},
   "source": [
    "# Extracting noun chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c8ab464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from Chapter01.dividing_into_sentences import read_text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b902f727",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_text_file(\"../Chapter01/sherlock_holmes_1.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df7718b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "51560281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock Holmes\n",
      "she\n",
      "the_ woman\n",
      "I\n",
      "him\n",
      "her\n",
      "any other name\n",
      "his eyes\n",
      "she\n",
      "the whole\n",
      "her sex\n",
      "It\n",
      "he\n",
      "any emotion\n",
      "Irene Adler\n",
      "All emotions\n",
      "his cold, precise but admirably balanced mind\n",
      "He\n",
      "I\n",
      "it\n",
      "the most perfect reasoning\n",
      "observing machine\n",
      "the world\n",
      "a lover\n",
      "he\n",
      "himself\n",
      "a\n",
      "false position\n",
      "He\n",
      "the softer passions\n",
      "a sneer\n",
      "They\n",
      "admirable things\n",
      "the observer\n",
      "the veil\n",
      "men’s motives\n",
      "actions\n",
      "the trained\n",
      "reasoner\n",
      "such intrusions\n",
      "his own delicate and finely\n",
      "adjusted temperament\n",
      "a distracting factor\n",
      "a doubt\n",
      "all his mental results\n",
      "Grit\n",
      "a sensitive\n",
      "instrument\n",
      "a crack\n",
      "his own high-power lenses\n",
      "a strong emotion\n",
      "a nature\n",
      "his\n",
      "but one woman\n",
      "him\n",
      "that woman\n",
      "the late Irene\n",
      "Adler\n",
      "dubious and questionable memory\n"
     ]
    }
   ],
   "source": [
    "# print out the noun chunks\n",
    "\n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5a08d6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0f47dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3d15d590",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "609c1224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions\n",
      "his cold, precise but admirably balanced mind\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "969486d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t 0 \t 2\n",
      "his cold, precise but admirably balanced mind \t 11 \t 19\n"
     ]
    }
   ],
   "source": [
    "# basic properties of noun chunks are its start and end offsets\n",
    "\n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, '\\t', noun_chunk.start, '\\t', noun_chunk.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "632adb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n",
      "his cold, precise but admirably balanced mind \t All emotions, and that one particularly, were abhorrent to his cold, precise but admirably balanced mind.\n"
     ]
    }
   ],
   "source": [
    "# print out the sentence where the noun chunk\n",
    "\n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, '\\t', noun_chunk.sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6be15079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All emotions \t emotions\n",
      "his cold, precise but admirably balanced mind \t mind\n"
     ]
    }
   ],
   "source": [
    "#  any noun chunk includes a root, which is the token that all other tokens depend on. \n",
    "# In a noun phrase, that is the noun:\n",
    "\n",
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.text, '\\t', noun_chunk.root.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "280ec91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# semantic similarity of different texts. \n",
    "\n",
    "other_span = \"emotions\"\n",
    "other_doc = nlp(other_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4061377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8876554549427152\n",
      "0.5102475977383759\n"
     ]
    }
   ],
   "source": [
    "for noun_chunk in doc.noun_chunks:\n",
    "    print(noun_chunk.similarity(other_doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0a78be",
   "metadata": {},
   "source": [
    "# Extracting entities and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b12033d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import textacy\n",
    "from Chapter02.split_into_clauses_3 import find_root_of_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "713f6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e6d9bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\"All living things are made of cells.\", \"Cells have organelles.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "06ee2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "verb_patterns = [[{\"POS\":\"AUX\"}, {\"POS\":\"VERB\"}, {\"POS\":\"ADP\"}], [{\"POS\":\"AUX\"}],[{\"POS\":\"VERB\"}]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a65fe98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The contains_root function checks if a verb phrase contains the root of the sentence:\n",
    "\n",
    "def contains_root(verb_phrase, root):\n",
    "    vp_start = verb_phrase.start\n",
    "    vp_end = verb_phrase.end-1\n",
    "    if (root.i >= vp_start and root.i <= vp_end):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b6e6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The get_verb_phrases function gets the verb phrases from a spaCy Doc object:\n",
    "\n",
    "def get_verb_phrases(doc):\n",
    "    root = find_root_of_sentence(doc)\n",
    "    verb_phrases = list(textacy.extract.matches.token_matches(doc, verb_patterns))\n",
    "    new_vps = []\n",
    "    for verb_phrase in verb_phrases:\n",
    "        if contains_root(verb_phrase,root):\n",
    "            new_vps.append(verb_phrase)\n",
    "    return new_vps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "247465eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The longer_verb_phrase function finds the longest verb phrase:\n",
    "\n",
    "def longer_verb_phrase(verb_phrases):\n",
    "    longest_length = 0\n",
    "    longest_verb_phrase = None\n",
    "    for verb_phrase in verb_phrases:\n",
    "        if len(verb_phrase) > longest_length:\n",
    "            longest_verb_phrase = verb_phrase\n",
    "    return longest_verb_phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a425c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The find_noun_phrase function will look for noun phrases \n",
    "# either on the left- or right-hand side of the main verb phrase:\n",
    "\n",
    "def find_noun_phrase(verb_phrase, noun_phrases, side):\n",
    "    for noun_phrase in noun_phrases:\n",
    "        if (side == \"left\" and noun_phrase.start < verb_phrase.start):\n",
    "            return noun_phrase\n",
    "        elif (side == \"right\" and noun_phrase.start > verb_phrase.start):\n",
    "            return noun_phrase\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "47d08a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_triplet(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    verb_phrases = get_verb_phrases(doc)\n",
    "    noun_phrases = doc.noun_chunks\n",
    "    verb_phrase = None\n",
    "    if (len(verb_phrases) > 1):\n",
    "        verb_phrase = longer_verb_phrase(list(verb_phrases))\n",
    "    else:\n",
    "        verb_phrase = verb_phrases[0]\n",
    "    left_noun_phrase = find_noun_phrase(verb_phrase,noun_phrases,\"left\")\n",
    "    right_noun_phrase = find_noun_phrase(verb_phrase,noun_phrases,\"right\")\n",
    "    return (left_noun_phrase,verb_phrase,right_noun_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "72cbf3c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All living things \t are made of \t cells\n",
      "Cells \t have \t organelles\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    (left_np, vp, right_np) = find_triplet(sentence)\n",
    "    print(left_np, \"\\t\", vp, \"\\t\", right_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465cacd",
   "metadata": {},
   "source": [
    "## Extracting subjects and objects of the sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6d5a111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b11ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=[\"The big black cat stared at the small dog.\",\n",
    "           \"Jane watched her brother in the evenings.\",\n",
    "          \"Laura gave Sam a very interesting book.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d1b4151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that find subtree that contains the token with subj or dobj in the dependency tag\n",
    "\n",
    "def get_subject_phrase(doc):\n",
    "    for token in doc:\n",
    "        if \"subj\" in token.dep_:\n",
    "            subtree = list(token.subtree)\n",
    "            start = subtree[0].i\n",
    "            end = subtree[-1].i + 1\n",
    "            return doc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a0ce990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# direct object function. If the sentence does not have a direct object, it will return None\n",
    "\n",
    "def get_object_phrase(doc):\n",
    "    for token in doc:\n",
    "        if \"dobj\" in token.dep_:\n",
    "            subtree = list(token.subtree)\n",
    "            start = subtree[0].i\n",
    "            end = subtree[-1].i + 1\n",
    "            return doc[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e3bea0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The big black cat\n",
      "None\n",
      "************\n",
      "Jane\n",
      "her brother\n",
      "************\n",
      "Laura\n",
      "a very interesting book\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    subject_phrase = get_subject_phrase(doc)\n",
    "    object_phrase = get_object_phrase(doc)\n",
    "    print(subject_phrase)\n",
    "    print(object_phrase)\n",
    "    print('************')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cb1ada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dative object function checks the tokens for the dative tag. It returns None if there are no dative objects:\n",
    "\n",
    "def get_dative_phrase(doc):\n",
    "    for token in doc:\n",
    "        if \"dative\" in token.dep_:\n",
    "            subtree = list(token.subtree)\n",
    "            start = subtree[0].i\n",
    "            end = subtree[-1].i + 1\n",
    "            return doc[start:end]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1a507f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the prepositional object function. It returns a list of objects of prepositions, but will be empty if there are none:\n",
    "\n",
    "def get_prepositional_phrase_objs(doc):\n",
    "    prep_spans = []\n",
    "    for token in doc:\n",
    "        if (\"pobj\" in token.dep_):\n",
    "            subtree = list(token.subtree)\n",
    "            start = subtree[0].i\n",
    "            end = subtree[-1].i + 1\n",
    "            prep_spans.append(doc[start:end])\n",
    "    return prep_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "735e38bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "[the small dog]\n",
      "************\n",
      "None\n",
      "[the evenings]\n",
      "************\n",
      "Sam\n",
      "[]\n",
      "************\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    dative_object_phrase = get_dative_phrase(doc)\n",
    "    prepositional_object_phrase = get_prepositional_phrase_objs(doc)\n",
    "    print(dative_object_phrase)\n",
    "    print(prepositional_object_phrase)\n",
    "    print('************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d17710c",
   "metadata": {},
   "source": [
    "## Finding references – anaphora resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfebb4c",
   "metadata": {},
   "source": [
    "* When we work on problems of extracting entities and relations from text. \n",
    "\n",
    "\n",
    "* we are faced with real text, and many of our entities might end up being extracted as pronouns, such as she or him. \n",
    "\n",
    "\n",
    "* In order to tackle this issue, we need to perform anaphora resolution, or the process of substituting the pronouns with their referents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9cfb7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91eef153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87c5b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9e0d4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fb1717d1910>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuralcoref.add_to_pipe(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09365908",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Earlier this year, Olga appeared on a new song. She was featured on one of the tracks.\\\n",
    "        The singer is assuring that her next album will be worth the wait.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3053ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earlier this year, Olga appeared on a new song. Olga was featured on one of the tracks.        Olga is assuring that Olga next album will be worth the wait.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "print(doc._.coref_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecfc4cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Deepika has a dog. She loves him. The movie star has always been fond of animals.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04d5f548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepika has a dog. Deepika loves Deepika. Deepika has always been fond of animals.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "print(doc._.coref_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa0ed7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x7fb176400f50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "neuralcoref.add_to_pipe(nlp, conv_dict={'Deepika': ['woman']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22573a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepika has a dog. Deepika loves a dog. Deepika has always been fond of animals.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "print(doc._.coref_resolved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3963f497",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
